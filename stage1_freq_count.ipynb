{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ebab20-e64d-4a31-965c-c6f984963b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import base64\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "from utils import make_context\n",
    "\n",
    "from langdetect import detect as langdetect\n",
    "from langdetect import DetectorFactory\n",
    "# 确保检测结果的一致性\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19c28c-5e14-4ef0-a010-6cf9894dd909",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Prepare Dataset ###########\n",
    "data_path = \"/home/z00533370/projects/VLMEvalKit/raw_data/\"\n",
    "\n",
    "def get_text_list(folder_path):\n",
    "    query_list = []\n",
    "    response_list = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith('json'):\n",
    "            file = json.load(open(os.path.join(folder_path, file_name)))\n",
    "            query_list.append(file['query'])\n",
    "            response_list.append(file['response'])\n",
    "    return query_list, response_list\n",
    "\n",
    "query_list, response_list = get_text_list(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2683ba-83cf-4263-8829-23a8be78d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Count Token Freqs ###########\n",
    "model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197/\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "token_counts = [0 for _ in range(151936)]\n",
    "assert len(query_list) == len(response_list)\n",
    "for i in tqdm(range(len(query_list))):\n",
    "    query, response = query_list[i], response_list[i]\n",
    "    _, context_tokens = make_context(tokenizer, query, history=[], system=\"You are a helpful assistant.\")\n",
    "    for token in context_tokens:\n",
    "        token_counts[token] += 1\n",
    "    response_tokens = tokenizer.encode(response)\n",
    "    for token in response_tokens:\n",
    "        token_counts[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed227660-901b-48d2-9221-fc3a9325dfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## update multi-byte to count to sub-token ###########\n",
    "tiktoken_bpe_file = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197/qwen.tiktoken\"\n",
    "with open(tiktoken_bpe_file, \"rb\") as f:\n",
    "    contents = f.read()\n",
    "old_token_list = [base64.b64decode(token) for token, rank in (line.split() for line in contents.splitlines() if line)]\n",
    "old_bytes_list = [token for token, rank in (line.split() for line in contents.splitlines() if line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0fbe6-ae2e-4ec4-af54-159558a782d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a list to calculate inherit_counts\n",
    "inherit_counts = [0 for _ in range(151936)]\n",
    "for i in tqdm(range(len(old_token_list))):\n",
    "    t_count = token_counts[i]\n",
    "    b_len = len(old_token_list[i])\n",
    "    if t_count > 0 and b_len > 1:\n",
    "        for j in range(1, b_len):\n",
    "            for k in range(b_len+1-j):\n",
    "                sub_token = old_token_list[i][k:j+k]\n",
    "                try:\n",
    "                    inherit_counts[old_token_list.index(sub_token)] += t_count\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc644754-ad87-4619-995c-2b66655a8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Dictionary Pruning ###########\n",
    "def is_special_token(token):\n",
    "    return ((token.startswith('<') and token.endswith('>') and len(token) > 2) or\n",
    "            (token.startswith('[') and token.endswith(']') and len(token) > 2))\n",
    "\n",
    "new_token_list = []\n",
    "new_bytes_list = []\n",
    "mapping_new2old = []\n",
    "# detect language, only keep english and chinese\n",
    "for i in tqdm(range(len(old_token_list))):\n",
    "    token = old_token_list[i]\n",
    "    try:\n",
    "        # number and symbols cannot be detected by langdetect\n",
    "        token_str = token.decode(\"utf-8\")\n",
    "        if (langdetect(token_str) in ['zh-cn', 'en']) or (token_counts[i] + inherit_counts[i] > 0) or is_special_token(token_str):\n",
    "        #if (token_counts[i] + inherit_counts[i] > 0) or is_special_token(token_str):\n",
    "        #if (token_counts[i] > 0) or is_special_token(token_str):\n",
    "            new_token_list.append(token)\n",
    "            new_bytes_list.append(old_bytes_list[i])\n",
    "            mapping_new2old.append(i)\n",
    "    except:\n",
    "        new_token_list.append(token)\n",
    "        new_bytes_list.append(old_bytes_list[i])\n",
    "        mapping_new2old.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754a7e1-0625-4937-812c-82a4a71c3d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Add Special Token Mapping ###########\n",
    "qwen_vocab_size = 151936\n",
    "for i in range(len(old_token_list), qwen_vocab_size):\n",
    "    mapping_new2old.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4172a5f-14f2-495c-b211-f9e1964c6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mapping_new2old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a7c14-b8f6-4c24-84d3-b61717e2c2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Save New Vocab ###########\n",
    "new_tiktoken_bpe_file = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197-new-vocab/qwen.tiktoken\"\n",
    "vocab_mapping_file = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197-new-vocab/token_vocab_mapping.torch\"\n",
    "# saving new tiktoken_bpe_file\n",
    "with open(new_tiktoken_bpe_file, \"w\", encoding=\"utf8\") as w:\n",
    "    for i, token in enumerate(new_token_list):\n",
    "        line = base64.b64encode(token).decode(\"utf8\") + \" \" + str(i) + \"\\n\"\n",
    "        w.write(line)\n",
    "# saving mapping index\n",
    "torch.save(torch.LongTensor(mapping_new2old), vocab_mapping_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d95769-a653-4b2e-b2cc-85311204f8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## update model ###########\n",
    "old_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197/\"\n",
    "new_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197-new-vocab/\"\n",
    "model = AutoModelForCausalLM.from_pretrained(old_model_path, trust_remote_code=True)\n",
    "# define new module\n",
    "new_embeds = torch.nn.Embedding(len(mapping_new2old), model.config.hidden_size, dtype=model.transformer.wte.weight.dtype)\n",
    "new_lm_head = torch.nn.Linear(model.config.hidden_size, len(mapping_new2old), bias=False, dtype=model.lm_head.weight.dtype)\n",
    "# get new module parameter from the old\n",
    "assert len(set(mapping_new2old)) == len(mapping_new2old)\n",
    "new_embeds.weight.data = model.transformer.wte.weight.data[torch.LongTensor(mapping_new2old, device=model.device)]\n",
    "new_lm_head.weight.data = model.lm_head.weight.data[torch.LongTensor(mapping_new2old, device=model.device)]\n",
    "# update model\n",
    "model.transformer.wte.weight = new_embeds.weight\n",
    "model.lm_head.weight = new_lm_head.weight\n",
    "model.transformer.wte.num_embeddings = len(mapping_new2old)\n",
    "model.lm_head.out_features = len(mapping_new2old)\n",
    "# update config\n",
    "model.config.__dict__['vocab_size'] = len(mapping_new2old)\n",
    "model.config.__dict__['_name_or_path'] = new_model_path\n",
    "model.config.__dict__['visual'][\"image_start_id\"] = mapping_new2old.index(model.config.__dict__['visual'][\"image_start_id\"])\n",
    "model.generation_config.__dict__['eos_token_id'] = mapping_new2old.index(model.generation_config.__dict__['eos_token_id'])\n",
    "model.generation_config.__dict__['pad_token_id'] = mapping_new2old.index(model.generation_config.__dict__['pad_token_id'])\n",
    "# save new model\n",
    "model.save_pretrained(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e13804-6318-475a-bb21-5ee353327f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197/\"\n",
    "new_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197-new-vocab/\"\n",
    "\n",
    "old_model = AutoModelForCausalLM.from_pretrained(old_model_path, trust_remote_code=True).eval()\n",
    "new_model = AutoModelForCausalLM.from_pretrained(new_model_path, trust_remote_code=True).eval()\n",
    "\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(old_model_path, trust_remote_code=True)\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(new_model_path, trust_remote_code=True)\n",
    "\n",
    "old_model = old_model.cuda(5)\n",
    "new_model = new_model.cuda(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b11d51-8c3f-4bc6-9fc3-ab2b03a1d6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, old_context_tokens = make_context(old_tokenizer, query_list[0], history=[], system=\"You are a helpful assistant.\")\n",
    "_, new_context_tokens = make_context(new_tokenizer, query_list[0], history=[], system=\"You are a helpful assistant.\")\n",
    "\n",
    "old_input_ids = torch.tensor([old_context_tokens]).to(old_model.device)\n",
    "new_input_ids = torch.tensor([new_context_tokens]).to(new_model.device)\n",
    "\n",
    "old_output = old_model(old_input_ids, output_hidden_states=True)\n",
    "new_output = new_model(new_input_ids, output_hidden_states=True)\n",
    "\n",
    "old_output_2 = old_model(old_input_ids, output_hidden_states=True)\n",
    "new_output_2 = new_model(new_input_ids, output_hidden_states=True)\n",
    "#old_result = old_model.chat(old_tokenizer, query=query_list[0], history=None)\n",
    "#new_result = new_model.chat(new_tokenizer, query=query_list[0], history=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c051f1-001a-4528-ab84-445885a72f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(old_model.transformer.wte(old_input_ids) == new_model.transformer.wte(new_input_ids)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2320f5f8-34df-4180-b840-d977331df76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(old_output.hidden_states[-1] == new_output.hidden_states[-1]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa72a8-bec5-491d-95f6-e7ddc3f2200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(old_output.logits.max(-1)[0] == new_output.logits.max(-1)[0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cd6e51-790d-4865-8732-3b475a98e45b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_output.logits.max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9500e9ba-fdcc-45de-ae1d-b54c6d822e5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_output.logits.max(-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c54da8-b135-4068-967a-b3c0d4d957ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_new2old.index(136992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1177ec04-1887-4a52-af97-bd095c5d58c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197/\"\n",
    "old_tokenizer = AutoTokenizer.from_pretrained(old_model_path, trust_remote_code=True)\n",
    "\n",
    "new_model_path = \"/home/z00533370/projects/MoH/exp0731_qwenvl_chat_moh_layer16-31_sigmoid_prob_no_norm/checkpoint-5197-new-vocab/\"\n",
    "new_tokenizer = AutoTokenizer.from_pretrained(new_model_path, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91f6c1-78a8-449e-b9ab-5076697cdbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(query_list)):\n",
    "    item = query_list[i]\n",
    "    old_result = old_tokenizer.encode(item)\n",
    "    new_result = new_tokenizer.encode(item)\n",
    "    new_result = [mapping_new2old[i] for i in new_result]\n",
    "    \n",
    "    if len(old_result) != len(new_result):\n",
    "        print(i)\n",
    "    \n",
    "    for old_token, new_token in zip(old_result, new_result):\n",
    "        if old_token != new_token:\n",
    "            print(i)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3748df61-f075-47b9-9ad4-ac2a52eea65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_result = old_tokenizer.encode(query_list[26])\n",
    "print(len(old_result))\n",
    "\n",
    "new_result = new_tokenizer.encode(query_list[26])\n",
    "new_result = [mapping_new2old[i] for i in new_result]\n",
    "print(len(new_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61921a2c-fb73-44e9-b843-a8dc9ff32990",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_result)):\n",
    "    if old_result[i] != new_result[i]:\n",
    "        print(i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d16719-e2b8-4b94-b356-c0e59d9872e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_result[344:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e422ae-59ea-43dd-9e97-d30d9cb27e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result[344:350]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c94cce-d669-4bbc-8a99-36fc279e54e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_token_list[136992]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e21d7f0-0500-462d-bb8a-4ed3ce43770f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_token_list[291], old_token_list[70], old_token_list[288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3c8a6-d250-47a2-ac69-c56fa7eccb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token_list.index(b'ges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a523c7-cfa2-42aa-8bec-9033f46eadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_len = len(old_token_list[16900])\n",
    "sub_token_list = []\n",
    "for j in range(1, b_len):\n",
    "    for k in range(b_len+1-j):\n",
    "        sub_token = old_token_list[16900][k:j+k]\n",
    "        sub_token_list.append(sub_token)\n",
    "sub_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba314e-53f5-474c-89ba-e249831ae7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer.decode([136992])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0004b05a-5e54-4c22-a66a-9fdad98c0a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "b'aXJ0' in old_bytes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f1dd08-8c3d-4089-8874-bed571a9448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b'aXJ0' in new_bytes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2f408-4d43-48e8-84a4-77c924bf5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_bytes_list[44904]\n",
    "#old_token_list[44904], old_token_list[30942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa31e2-4281-4b2d-81c9-103911255272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fee11e-5966-4327-ba85-5965ca16ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4699460f-08a9-4bc2-9f17-2b1215037a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "[mapping_new2old[i] for i in result[294:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cdac81-8ebe-4063-8027-61603ddf124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {}\n",
    "a[('c', 'd')] = 1\n",
    "a[('c', 'd')] += 1\n",
    "a[('c', 'd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e961d1-da91-4eb2-a4cb-5e4cbd46c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_bytes_list[404], old_bytes_list[665], old_bytes_list[268]\n",
    "old_token_list[404], old_token_list[665], old_token_list[268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78414ffb-76d7-4758-b69c-436a10ae11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, item in enumerate([mapping_new2old[i] for i in result]):\n",
    "    if old_result[i] != item:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e613f0-a6a9-4a6c-a92e-60e42ef50a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, item in enumerate(query_list):\n",
    "    if len(old_tokenizer.encode(item)) != len(tokenizer.encode(item)):\n",
    "        print(i)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63637962-d1ee-45cb-8392-cf3b27709810",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddb6bd-0a9a-4a6d-94f1-1c37a4b06b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(\"\"\"Hint: People can use the engineering-design process to develop solutions to problems. One step in the process is testing if a potential solution meets the requirements of the design.\n",
    "The passage below describes how the engineering-design process was used to test a solution to a problem. Read the passage. Then answer the question below.\n",
    "\n",
    "Devin was a mechanical engineer who was designing  to record temperature, precipitation, and wind speed. The weather station would be used in a town where the highest recorded temperature was 40¬∞C. Devin wanted to make sure the weather station would work even in unusually warm weather.\n",
    "So, he set an indoor test chamber to 50¬∞C with low moisture and no wind. He left the weather station in the chamber overnight. The next day, he checked to see if the weather station displayed accurate measurements after 24 hours at 50¬∞C.\n",
    "Figure: a weather station.\n",
    "Question: Which of the following could Devin's test show?\n",
    "Options:\n",
    "A. if the weather station would work when the temperature was 50¬∞C\n",
    "B. how well the weather station would work when it was windy\n",
    "Please select the correct answer from the options above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6b1d20-5599-405d-a820-b148d6c62bf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, item in enumerate(old_token_list):\n",
    "    try:\n",
    "        #print(i, item.decode('utf-8'))\n",
    "        item.decode('utf-8')\n",
    "    except:\n",
    "        print(i, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbac25ce-97ed-4da0-b24b-8e3299b1ef9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffc19e-db7f-411b-b9fe-71595d43fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(token_counts, 'token_counts.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67868b13-0657-4d1f-8355-293aad1f97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"token_counts.txt\", \"w\") as file:\n",
    "    for item in token_counts:\n",
    "        file.write(f\"{item}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d8e39d-c05b-437e-9670-f03cd630c34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765eac28-9cd8-4f28-8ba1-689940be4bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
